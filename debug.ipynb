{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6MPjfT5NrKQ"
   },
   "source": [
    "# Jupyter notebook for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "e8225db4-e61d-4640-8b1f-8bfce3331cea"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Copied from `train` function in train_simple.py:L78\n",
    "import yaml\n",
    "\n",
    "device = 'cpu'\n",
    "hyp = 'data/hyps/hyp.scratch-low.yaml'\n",
    "\n",
    "with open(hyp, errors=\"ignore\") as f:\n",
    "    hyp = yaml.safe_load(f)  # load hyps dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset not found ‚ö†Ô∏è, missing paths ['/home/a/hyu/aue8088-pa2/datasets/nuscenes/val.txt']\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/VOCtrainval_06-Nov-2007.zip to /home/a/hyu/aue8088-pa2/datasets/nuscenes/images/VOCtrainval_06-Nov-2007.zip...\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/VOCtest_06-Nov-2007.zip to /home/a/hyu/aue8088-pa2/datasets/nuscenes/images/VOCtest_06-Nov-2007.zip...\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/VOCtrainval_11-May-2012.zip to /home/a/hyu/aue8088-pa2/datasets/nuscenes/images/VOCtrainval_11-May-2012.zip...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/a/hyu/aue8088-pa2/datasets/nuscenes/images/VOCdevkit/VOC2012/ImageSets/Main/train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/yolov5n_nuscenes.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/nuscenes.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m nc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(data_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnc\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# number of classes\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(cfg, ch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, nc\u001b[38;5;241m=\u001b[39mnc, anchors\u001b[38;5;241m=\u001b[39mhyp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manchors\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# create\u001b[39;00m\n",
      "File \u001b[0;32m~/hyu/aue8088-pa2/utils/general.py:577\u001b[0m, in \u001b[0;36mcheck_dataset\u001b[0;34m(data, autodownload)\u001b[0m\n\u001b[1;32m    575\u001b[0m     r \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun(s, shell\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# python script\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# return None\u001b[39;00m\n\u001b[1;32m    578\u001b[0m dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess ‚úÖ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolorstr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39mDATASETS_DIR)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailure \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ‚ùå\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m<string>:47\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/a/hyu/aue8088-pa2/datasets/nuscenes/images/VOCdevkit/VOC2012/ImageSets/Main/train.txt'"
     ]
    }
   ],
   "source": [
    "from models.yolo import Model\n",
    "from utils.general import check_dataset\n",
    "\n",
    "cfg = 'models/yolov5n_nuscenes.yaml'\n",
    "data = 'data/nuscenes.yaml'\n",
    "data_dict = check_dataset(data)\n",
    "\n",
    "nc = int(data_dict[\"nc\"])  # number of classes\n",
    "model = Model(cfg, ch=3, nc=nc, anchors=hyp.get(\"anchors\")).to(device)  # create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = model.model[-1].anchors\n",
    "\n",
    "# [TODO] Draw anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ubuntu/datasets/nuscenes_det2d/train... 28130 images, 1425 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28130/28130 [00:01<00:00, 20217.09it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/ubuntu/datasets/nuscenes_det2d/train.cache\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloaders import create_dataloader\n",
    "from utils.general import check_img_size, colorstr\n",
    "\n",
    "imgsz = 416\n",
    "batch_size = 1\n",
    "single_cls = False\n",
    "seed = 0\n",
    "\n",
    "train_path = data_dict[\"train\"]\n",
    "gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n",
    "imgsz = check_img_size(imgsz, gs, floor=gs * 2)  # verify imgsz is gs-multiple\n",
    "\n",
    "train_loader, dataset = create_dataloader(\n",
    "    train_path,\n",
    "    imgsz,\n",
    "    batch_size,\n",
    "    gs,\n",
    "    single_cls,\n",
    "    hyp=hyp,\n",
    "    augment=True,\n",
    "    cache=None,\n",
    "    rect=False,\n",
    "    rank=-1,\n",
    "    workers=8,\n",
    "    image_weights=False,\n",
    "    quad=False,\n",
    "    prefix=colorstr(\"train: \"),\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, targets, paths, _ in train_loader:\n",
    "    imgs = imgs.to(device, non_blocking=True).float() / 255  # uint8 to float32, 0-255 to 0.0-1.0\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 üöÄ v7.0-320-g77b4eb3a Python-3.10.12 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.torch_utils import select_device\n",
    "\n",
    "weights = 'yolov5n.pt'\n",
    "# data = 'data/nuscenes.yaml'\n",
    "data = 'data/coco128.yaml'\n",
    "half = False  # use FP16 half-precision inference\n",
    "dnn = False  # use OpenCV DNN for ONNX inference\n",
    "device = select_device('cpu')\n",
    "\n",
    "model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
    "\n",
    "# inference\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(imgs)  # forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.general import non_max_suppression\n",
    "\n",
    "conf_thres = 0.25  # confidence threshold\n",
    "iou_thres = 0.45  # NMS IOU threshold\n",
    "max_det = 1000  # maximum detections per image\n",
    "classes = None\n",
    "agnostic_nms = False  # class-agnostic NMS\n",
    "\n",
    "pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "\n",
    "# [TODO] draw predictions (see detect.py:L178)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "YOLOv5 Tutorial",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
